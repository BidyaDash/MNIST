{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport torch\nimport torchvision\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom IPython.display import display\nfrom torch.utils.data import DataLoader\nfrom sklearn.model_selection import train_test_split # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":21,"outputs":[{"output_type":"stream","text":"/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n/kaggle/input/digit-recognizer/sample_submission.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\ndf.head(4)","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n\n[4 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 785 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"training_data = torch.tensor(df.values)\nlabels_data = torch.tensor(df[\"label\"])\n","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(training_data, labels_data, test_size=0.2)","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape, y_train.shape)\nprint(X_val.shape, y_val.shape)\n","execution_count":25,"outputs":[{"output_type":"stream","text":"torch.Size([33600, 785]) torch.Size([33600])\ntorch.Size([8400, 785]) torch.Size([8400])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(X_train, batch_size = 32, shuffle = True)\nval_loader = DataLoader(X_val, batch_size = 32, shuffle = True)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"USE_GPU = True\ndtype = torch.float32\nif USE_GPU and torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n\nprint('using device:', device)","execution_count":27,"outputs":[{"output_type":"stream","text":"using device: cuda\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size = 5, bias = True),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2),\n            \n            nn.Conv2d(32, 64, kernel_size = 3, bias = True),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 1),    \n            \n            nn.Flatten(),\n            nn.Linear(64 * 9 * 9, 128),\n            nn.ReLU(),\n    \n            nn.Linear(128, 10),\n            \n                          )","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 30\noptimizer = optim.Adam(model.parameters(), lr=2e-4)\ndtype = torch.float32","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model.to(device=device)\nPATH = \"/kaggle/working/best_model.pth\"\nbest_accuracy = 0\n\nfor e in range(epochs):\n    model.train()\n    training_accuracy = 0\n    validation_accuracy = 0  \n    loss_list = []\n    denom_train = 0\n    denom_val = 0\n    print(\"EPOCH: \", e + 1)\n    for (t, data) in enumerate(train_loader):\n        optimizer.zero_grad()\n        \n        input_array = data[:,1:]/255.0        \n        target = data[:,0]\n        \n        input_array = input_array.reshape(len(target),28,28).unsqueeze(1)\n        \n        input_array = input_array.to(device=device, dtype = dtype)  \n        target = target.to(device=device)\n        \n        scores = model(input_array)\n        predict = nn.LogSoftmax()\n        predictions = predict(scores)\n        predictions = torch.argmax(predictions, axis = 1)\n        \n        \n        loss = nn.functional.cross_entropy(scores, target)\n        loss.backward()\n\n        optimizer.step()\n        \n        training_accuracy += sum(target == predictions).item()\n        denom_train += target.shape[0]\n        loss_list.append(loss.item())\n    \n    print(\"Got {}/{} correct\".format(training_accuracy, denom_train))\n    print(\"Loss = {:.4f}, Epoch Training Accuracy = {:.4f}\\n\".format(sum(loss_list) / len(loss_list), \n                                                                   ((training_accuracy / denom_train) * 100)))\n    for (t_val, data_val) in enumerate(val_loader):    \n        input_array_val = data_val[:,1:]/255.0        \n        target_val = data_val[:,0]\n        input_array_val = input_array_val.reshape(len(target_val),28,28).unsqueeze(1)\n        \n        input_array_val = input_array_val.to(device=device, dtype = dtype)  \n        target_val = target_val.to(device=device)\n        \n        \n        scores_val = model(input_array_val)\n        predict_val = nn.LogSoftmax()\n        predictions_val = predict_val(scores_val)\n        predictions_val = torch.argmax(predictions_val, axis = 1)\n        \n        validation_accuracy += sum(target_val == predictions_val).item()\n        denom_val += target_val.shape[0]\n        \n    \n    print(\"Got {}/{} correct\".format(validation_accuracy, denom_val))\n    print(\"Epoch Validation Accuracy = {:.4f}\\n\".format((validation_accuracy / denom_val) * 100))\n    \n    if (validation_accuracy / denom_val) * 100 > best_accuracy:\n        print(\"Saving the best model.......\")\n        best_accuracy = (validation_accuracy / denom_val) * 100\n        torch.save(model, PATH)\n\nprint(\"Training Over\")\n\n        \n","execution_count":32,"outputs":[{"output_type":"stream","text":"EPOCH:  1\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","name":"stderr"},{"output_type":"stream","text":"Got 33453/33600 correct\nLoss = 0.0125, Epoch Training Accuracy = 99.5625\n\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:53: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","name":"stderr"},{"output_type":"stream","text":"Got 8279/8400 correct\nEpoch Validation Accuracy = 98.5595\n\nSaving the best model.......\nEPOCH:  2\nGot 33494/33600 correct\nLoss = 0.0086, Epoch Training Accuracy = 99.6845\n\nGot 8282/8400 correct\nEpoch Validation Accuracy = 98.5952\n\nSaving the best model.......\nEPOCH:  3\nGot 33478/33600 correct\nLoss = 0.0099, Epoch Training Accuracy = 99.6369\n\nGot 8305/8400 correct\nEpoch Validation Accuracy = 98.8690\n\nSaving the best model.......\nEPOCH:  4\nGot 33522/33600 correct\nLoss = 0.0075, Epoch Training Accuracy = 99.7679\n\nGot 8286/8400 correct\nEpoch Validation Accuracy = 98.6429\n\nEPOCH:  5\nGot 33494/33600 correct\nLoss = 0.0089, Epoch Training Accuracy = 99.6845\n\nGot 8295/8400 correct\nEpoch Validation Accuracy = 98.7500\n\nEPOCH:  6\nGot 33494/33600 correct\nLoss = 0.0119, Epoch Training Accuracy = 99.6845\n\nGot 8302/8400 correct\nEpoch Validation Accuracy = 98.8333\n\nEPOCH:  7\nGot 33544/33600 correct\nLoss = 0.0061, Epoch Training Accuracy = 99.8333\n\nGot 8314/8400 correct\nEpoch Validation Accuracy = 98.9762\n\nSaving the best model.......\nEPOCH:  8\nGot 33541/33600 correct\nLoss = 0.0057, Epoch Training Accuracy = 99.8244\n\nGot 8291/8400 correct\nEpoch Validation Accuracy = 98.7024\n\nEPOCH:  9\nGot 33495/33600 correct\nLoss = 0.0082, Epoch Training Accuracy = 99.6875\n\nGot 8310/8400 correct\nEpoch Validation Accuracy = 98.9286\n\nEPOCH:  10\nGot 33537/33600 correct\nLoss = 0.0062, Epoch Training Accuracy = 99.8125\n\nGot 8310/8400 correct\nEpoch Validation Accuracy = 98.9286\n\nEPOCH:  11\nGot 33551/33600 correct\nLoss = 0.0052, Epoch Training Accuracy = 99.8542\n\nGot 8298/8400 correct\nEpoch Validation Accuracy = 98.7857\n\nEPOCH:  12\nGot 33515/33600 correct\nLoss = 0.0069, Epoch Training Accuracy = 99.7470\n\nGot 8305/8400 correct\nEpoch Validation Accuracy = 98.8690\n\nEPOCH:  13\nGot 33550/33600 correct\nLoss = 0.0047, Epoch Training Accuracy = 99.8512\n\nGot 8298/8400 correct\nEpoch Validation Accuracy = 98.7857\n\nEPOCH:  14\nGot 33537/33600 correct\nLoss = 0.0064, Epoch Training Accuracy = 99.8125\n\nGot 8309/8400 correct\nEpoch Validation Accuracy = 98.9167\n\nEPOCH:  15\nGot 33544/33600 correct\nLoss = 0.0045, Epoch Training Accuracy = 99.8333\n\nGot 8294/8400 correct\nEpoch Validation Accuracy = 98.7381\n\nEPOCH:  16\nGot 33527/33600 correct\nLoss = 0.0074, Epoch Training Accuracy = 99.7827\n\nGot 8291/8400 correct\nEpoch Validation Accuracy = 98.7024\n\nEPOCH:  17\nGot 33569/33600 correct\nLoss = 0.0028, Epoch Training Accuracy = 99.9077\n\nGot 8312/8400 correct\nEpoch Validation Accuracy = 98.9524\n\nEPOCH:  18\nGot 33550/33600 correct\nLoss = 0.0041, Epoch Training Accuracy = 99.8512\n\nGot 8297/8400 correct\nEpoch Validation Accuracy = 98.7738\n\nEPOCH:  19\nGot 33548/33600 correct\nLoss = 0.0037, Epoch Training Accuracy = 99.8452\n\nGot 8298/8400 correct\nEpoch Validation Accuracy = 98.7857\n\nEPOCH:  20\nGot 33542/33600 correct\nLoss = 0.0050, Epoch Training Accuracy = 99.8274\n\nGot 8295/8400 correct\nEpoch Validation Accuracy = 98.7500\n\nEPOCH:  21\nGot 33576/33600 correct\nLoss = 0.0026, Epoch Training Accuracy = 99.9286\n\nGot 8315/8400 correct\nEpoch Validation Accuracy = 98.9881\n\nSaving the best model.......\nEPOCH:  22\nGot 33526/33600 correct\nLoss = 0.0060, Epoch Training Accuracy = 99.7798\n\nGot 8316/8400 correct\nEpoch Validation Accuracy = 99.0000\n\nSaving the best model.......\nEPOCH:  23\nGot 33566/33600 correct\nLoss = 0.0031, Epoch Training Accuracy = 99.8988\n\nGot 8271/8400 correct\nEpoch Validation Accuracy = 98.4643\n\nEPOCH:  24\nGot 33563/33600 correct\nLoss = 0.0037, Epoch Training Accuracy = 99.8899\n\nGot 8296/8400 correct\nEpoch Validation Accuracy = 98.7619\n\nEPOCH:  25\nGot 33577/33600 correct\nLoss = 0.0024, Epoch Training Accuracy = 99.9315\n\nGot 8315/8400 correct\nEpoch Validation Accuracy = 98.9881\n\nEPOCH:  26\nGot 33544/33600 correct\nLoss = 0.0045, Epoch Training Accuracy = 99.8333\n\nGot 8300/8400 correct\nEpoch Validation Accuracy = 98.8095\n\nEPOCH:  27\nGot 33553/33600 correct\nLoss = 0.0043, Epoch Training Accuracy = 99.8601\n\nGot 8312/8400 correct\nEpoch Validation Accuracy = 98.9524\n\nEPOCH:  28\nGot 33578/33600 correct\nLoss = 0.0023, Epoch Training Accuracy = 99.9345\n\nGot 8306/8400 correct\nEpoch Validation Accuracy = 98.8810\n\nEPOCH:  29\nGot 33563/33600 correct\nLoss = 0.0039, Epoch Training Accuracy = 99.8899\n\nGot 8295/8400 correct\nEpoch Validation Accuracy = 98.7500\n\nEPOCH:  30\nGot 33582/33600 correct\nLoss = 0.0016, Epoch Training Accuracy = 99.9464\n\nGot 8318/8400 correct\nEpoch Validation Accuracy = 99.0238\n\nSaving the best model.......\nTraining Over\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\ndf_test.head(4)","execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0       0       0       0       0       0       0       0       0       0   \n1       0       0       0       0       0       0       0       0       0   \n2       0       0       0       0       0       0       0       0       0   \n3       0       0       0       0       0       0       0       0       0   \n\n   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n\n[4 rows x 784 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 784 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = torch.tensor(df_test.values)\nprint(test_data.shape)","execution_count":34,"outputs":[{"output_type":"stream","text":"torch.Size([28000, 784])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = torch.load(PATH)\n\noutput_list = []\nids_list = []\n# model.eval()\nnum_samples = test_data.shape[0]\n\nfor idx in range(num_samples):        \n    \n    input_array_test = (test_data[idx,:].unsqueeze(0))/255.0\n    input_array_test = input_array_test.reshape(28,28).unsqueeze(0).unsqueeze(1)\n    input_array_test = input_array_test.to(device=device, dtype = dtype)  \n        \n    scores_test = model(input_array_test)\n    predict_test = nn.LogSoftmax()\n    predictions_test = predict_test(scores_test)\n    predictions_test = torch.argmax(predictions_test, axis = 1)\n    \n#     image = test_data[idx,:].reshape(28,28)\n#     plt.imshow(image)\n#     plt.xlabel(predictions_test.item(), fontsize = 20)\n#     plt.show()\n    \n    ids_list.append(idx + 1)\n    output_list.append(predictions_test.item())\n        ","execution_count":35,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n  app.launch_new_instance()\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(output_list[:10])","execution_count":36,"outputs":[{"output_type":"stream","text":"[2, 0, 9, 0, 3, 7, 0, 3, 0, 3]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission = pd.DataFrame({\"ImageId\":ids_list, \"Label\":output_list})\ndisplay(df_submission.head(10))","execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":"   ImageId  Label\n0        1      2\n1        2      0\n2        3      9\n3        4      0\n4        5      3\n5        6      7\n6        7      0\n7        8      3\n8        9      0\n9       10      3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission.to_csv(\"predictions.csv\", index = False)","execution_count":38,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}